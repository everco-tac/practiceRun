{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 52, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jaydo/practiceRun/my-app/app/api/gptNotes/route.ts"],"sourcesContent":["import { NextResponse } from \"next/server\";\r\nimport OpenAI from \"openai\";\r\n\r\nconst systemPrompt = `We want a mesage that correlates to this field:`;\r\n\r\nexport async function POST(req: Request) {\r\n  const body = await req.json();\r\n  console.log(\"in backend, body is\", body);\r\n  const response = await fetch(\r\n    \"https://acqbotai.openai.azure.us/openai/deployments/gpt35turbo/chat/completions?api-version=2024-01-25\",\r\n    {\r\n      method: \"POST\",\r\n      headers: {\r\n        \"Content-Type\": \"application/json\",\r\n        \"api-key\": process.env.AZURE_OPENAI_KEY!, // securely use env var\r\n      },\r\n      body: JSON.stringify({\r\n        messages: body.messages, // expects [{ role: \"user\", content: \"...\" }, ...]\r\n        temperature: 0.7,\r\n      }),\r\n    }\r\n  ).catch((error) => {\r\n    console.error(\"Error fetching from Azure OpenAI:\", error);\r\n    return new Response(\"Error fetching from Azure OpenAI\", {\r\n      status: 500,\r\n    });\r\n  });\r\n  const data = await response.json();\r\n  console.log(\"in backend, data is\", data);\r\n  return new Response(JSON.stringify(data), {\r\n    headers: { \"Content-Type\": \"application/json\" },\r\n  });\r\n}\r\n\r\n\r\n// export async function POST(req: Request) {\r\n//     const openai = new OpenAI({\r\n//         apiKey: process.env.OPENAI_API_KEY,\r\n//     });\r\n//     const data = await req.json();\r\n//     const completion = await openai.chat.completions.create({\r\n//         messages: [\r\n//             {\r\n//                 role: \"system\",\r\n//                 content: systemPrompt,\r\n\r\n//             },\r\n            \r\n//             ...data,\r\n//         ],\r\n//         model: \"gpt-3.5-turbo\",\r\n//         stream: true\r\n//     });\r\n\r\n//     const stream = new ReadableStream({\r\n//         async start(controller) {\r\n//             const encoder = new TextEncoder();\r\n//             try {\r\n//                 for await (const chunk of completion) {\r\n//                     const content = chunk.choices[0]?.delta?.content;\r\n//                     if (content) {\r\n//                         const text = encoder.encode(content);\r\n//                         controller.enqueue(text);\r\n//                     }\r\n//                 }\r\n//             } finally {\r\n//                 controller.close();\r\n//             }\r\n//         }\r\n//     });\r\n\r\n//     return new NextResponse(stream);\r\n// }"],"names":[],"mappings":";;;AAGA,MAAM,eAAe,CAAC,+CAA+C,CAAC;AAE/D,eAAe,KAAK,GAAY;IACrC,MAAM,OAAO,MAAM,IAAI,IAAI;IAC3B,QAAQ,GAAG,CAAC,uBAAuB;IACnC,MAAM,WAAW,MAAM,MACrB,0GACA;QACE,QAAQ;QACR,SAAS;YACP,gBAAgB;YAChB,WAAW,QAAQ,GAAG,CAAC,gBAAgB;QACzC;QACA,MAAM,KAAK,SAAS,CAAC;YACnB,UAAU,KAAK,QAAQ;YACvB,aAAa;QACf;IACF,GACA,KAAK,CAAC,CAAC;QACP,QAAQ,KAAK,CAAC,qCAAqC;QACnD,OAAO,IAAI,SAAS,oCAAoC;YACtD,QAAQ;QACV;IACF;IACA,MAAM,OAAO,MAAM,SAAS,IAAI;IAChC,QAAQ,GAAG,CAAC,uBAAuB;IACnC,OAAO,IAAI,SAAS,KAAK,SAAS,CAAC,OAAO;QACxC,SAAS;YAAE,gBAAgB;QAAmB;IAChD;AACF,EAGA,6CAA6C;CAC7C,kCAAkC;CAClC,8CAA8C;CAC9C,UAAU;CACV,qCAAqC;CACrC,gEAAgE;CAChE,sBAAsB;CACtB,gBAAgB;CAChB,kCAAkC;CAClC,yCAAyC;CAEzC,iBAAiB;CAEjB,uBAAuB;CACvB,aAAa;CACb,kCAAkC;CAClC,uBAAuB;CACvB,UAAU;CAEV,0CAA0C;CAC1C,oCAAoC;CACpC,iDAAiD;CACjD,oBAAoB;CACpB,0DAA0D;CAC1D,wEAAwE;CACxE,qCAAqC;CACrC,gEAAgE;CAChE,oDAAoD;CACpD,wBAAwB;CACxB,oBAAoB;CACpB,0BAA0B;CAC1B,sCAAsC;CACtC,gBAAgB;CAChB,YAAY;CACZ,UAAU;CAEV,uCAAuC;CACvC,IAAI","debugId":null}}]
}